server.port=8080
#chatmodel
langchain4j.ollama.chat-model.base-url=http://192.168.0.106:11434
langchain4j.ollama.chat-model.model-name=JollyLlama/llama3-8b-chinese-chat-q4-0-v2-1
langchain4j.ollama.chat-model.max-tokens=20
langchain4j.ollama.chat-model.temperature=0.7
langchain4j.ollama.chat-model.timeout=360000
#streaming-chatmodel
langchain4j.ollama.streaming-chat-model.base-url=http://192.168.0.106:11434
langchain4j.ollama.streaming-chat-model.model-name=JollyLlama/llama3-8b-chinese-chat-q4-0-v2-1
langchain4j.ollama.streaming-chat-model.max-tokens=20
langchain4j.ollama.streaming-chat-model.temperature=0.7
#embedding
langchain4j.ollama.embedding-model.base-url=http://192.168.0.106:11434
langchain4j.ollama.embedding-model.model-name=nomic-embed-text
#milvus
abigfish.milvus.url=http://192.168.2.220:19530
abigfish.milvus.collection-name=vector_store_9
abigfish.milvus.embedding-dimension=768
abigfish.milvus.metric-type=IP
abigfish.milvus.index-type=FLAT
#log
logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG
logging.level.org.abigfish=DEBUG
logging.level.org.springframework=info