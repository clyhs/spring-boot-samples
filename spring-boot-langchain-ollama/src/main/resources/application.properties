server.port=8080
#chatmodel
langchain4j.ollama.chat-model.base-url=http://192.168.0.106:11434
langchain4j.ollama.chat-model.model-name=llama2-chinese:13b
langchain4j.ollama.chat-model.max-tokens=20
langchain4j.ollama.chat-model.temperature=0.7
langchain4j.ollama.chat-model.timeout=36000
#streaming-chatmodel
langchain4j.ollama.streaming-chat-model.base-url=http://192.168.0.106:11434
langchain4j.ollama.streaming-chat-model.model-name=llama2-chinese:13b
langchain4j.ollama.streaming-chat-model.max-tokens=20
langchain4j.ollama.streaming-chat-model.temperature=0.7
#embedding
langchain4j.ollama.embedding-model.base-url=http://192.168.0.106:11434
langchain4j.ollama.embedding-model.model-name=llama2-chinese:13b
#milvus
abigfish.milvus.url=http://192.168.2.220:19530
abigfish.milvus.collection-name=vector_store_8
abigfish.milvus.embedding-dimension=5120
abigfish.milvus.metric-type=IP
abigfish.milvus.index-type=FLAT
#log
logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG
logging.level.org.springframework=info